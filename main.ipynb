{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "1. Zamiana sstas w KNN na cos sensowniejszego (done) zmieniełem na średnią\n",
    "2. Zrobic KNN z kubełkami. (zrobione)\n",
    "3. W np. logistic regression,knn dawać średnie zamiast losowych wartości.\n",
    "4. wykresy \n",
    "5. ridge regression\n",
    "6. random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7gn4siNptU4U"
   },
   "outputs": [],
   "source": [
    "# Please note that this code needs only to be run in a fresh runtime.\n",
    "# However, it can be rerun afterwards too.\n",
    "!pip install -q gdown httpimport\n",
    "# Standard IPython notebook imports\n",
    "import itertools\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as sopt\n",
    "import scipy.stats as sstats\n",
    "import seaborn as sns\n",
    "import sklearn.ensemble\n",
    "import sklearn.tree\n",
    "from sklearn import datasets\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as pltdef\n",
    "import httpimport\n",
    "from PIL import Image\n",
    "import glob\n",
    "# In this way we can import functions straight from github\n",
    "with httpimport.github_repo(\n",
    "    \"janchorowski\", \"nn_assignments\", module=\"common\", branch=\"nn18\"\n",
    "):\n",
    "    from common.gradients import check_gradient\n",
    "    from common.plotting import plot_mat\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JxjtXjFFtYYs"
   },
   "outputs": [],
   "source": [
    "\n",
    "def KNN(train_X, train_Y, test_X, ks, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute predictions for various k\n",
    "    Args:\n",
    "        train_X: array of shape Ntrain x D\n",
    "        train_Y: array of shape Ntrain\n",
    "        test_X: array of shape Ntest x D\n",
    "        ks: list of integers\n",
    "    Returns:\n",
    "        preds: dict k: predictions for k\n",
    "    \"\"\"\n",
    "    # Cats data to float32\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    test_X = test_X.astype(np.float32)\n",
    "\n",
    "    # Alloc space for results\n",
    "    preds = {}\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing distances... \", end='')\n",
    "    #\n",
    "    # TODO: fill in an efficient distance matrix computation\n",
    "    #    \n",
    "    #dists = np.linalg.norm((train_X[:, None] - test_X), axis = -1)\n",
    "    dists = np.sqrt((train_X**2).sum(1)[:,None] + (test_X**2).sum(1) - 2*train_X.dot(test_X.T))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Sorting... \", end='')\n",
    "    \n",
    "    # TODO: findes closest trainig points\n",
    "    # Hint: use argsort\n",
    "    closest = np.argsort(dists, axis = 0)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing predictions...\", end='')\n",
    "    \n",
    "    targets = train_Y[closest]\n",
    "\n",
    "    for k in ks:\n",
    "        predictions = sstats.tmean(targets[:k])\n",
    "        #Bierzemy średnią zamiast najczęściej występującej wartości\n",
    "        preds[k] = predictions\n",
    "    if verbose:\n",
    "        print(\"Done\")\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0JwUeu8vANV",
    "outputId": "9c765e6a-771b-4fdf-8e0f-204707e21d6f"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "WB55ZHgpyr6V",
    "outputId": "45f74b60-f7ae-4d76-f9d7-7ac5f5883c38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>ffbfa0383c34dc513c95560d6e1fdb57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9908</th>\n",
       "      <td>ffcc8532d76436fc79e50eb2e5238e45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>ffdf2e8673a1da6fb80342fa3b119a20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>fff19e2ce11718548fa1c5d039a5192a</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>fff8e47c766799c9e12f3cb3d66ad228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9912 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Id  Subject Focus  Eyes  Face  Near  \\\n",
       "0     0007de18844b0dbbb5e1f607da0606e0              0     1     1     1   \n",
       "1     0009c66b9439883ba2750fb825e1d7db              0     1     1     0   \n",
       "2     0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1   \n",
       "3     0018df346ac9c1d8413cfcc888ca8246              0     1     1     1   \n",
       "4     001dc955e10590d3ca4673f034feeef2              0     0     0     1   \n",
       "...                                ...            ...   ...   ...   ...   \n",
       "9907  ffbfa0383c34dc513c95560d6e1fdb57              0     0     0     1   \n",
       "9908  ffcc8532d76436fc79e50eb2e5238e45              0     1     1     1   \n",
       "9909  ffdf2e8673a1da6fb80342fa3b119a20              0     1     1     1   \n",
       "9910  fff19e2ce11718548fa1c5d039a5192a              0     1     1     1   \n",
       "9911  fff8e47c766799c9e12f3cb3d66ad228              0     1     1     1   \n",
       "\n",
       "      Action  Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          0          0      1        0      0          0     0     0   \n",
       "1          0          0      0        0      0          0     0     0   \n",
       "2          0          0      0        0      1          1     0     0   \n",
       "3          0          0      0        0      0          0     0     0   \n",
       "4          0          0      1        0      0          0     0     0   \n",
       "...      ...        ...    ...      ...    ...        ...   ...   ...   \n",
       "9907       0          0      0        0      0          0     0     1   \n",
       "9908       0          0      0        0      0          0     0     0   \n",
       "9909       0          0      0        0      1          1     0     0   \n",
       "9910       0          0      0        0      1          0     0     0   \n",
       "9911       0          0      0        0      0          0     0     0   \n",
       "\n",
       "      Pawpularity    C  \n",
       "0              63  1.0  \n",
       "1              42  1.0  \n",
       "2              28  1.0  \n",
       "3              15  1.0  \n",
       "4              72  1.0  \n",
       "...           ...  ...  \n",
       "9907           15  1.0  \n",
       "9908           70  1.0  \n",
       "9909           20  1.0  \n",
       "9910           20  1.0  \n",
       "9911           30  1.0  \n",
       "\n",
       "[9912 rows x 15 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./petfinder-pawpularity-score/train.csv\")\n",
    "train_df[\"C\"] = np.ones(9912)\n",
    "test_df = pd.read_csv(\"./petfinder-pawpularity-score/test.csv\")\n",
    "test_df[\"Pawpularity\"] = pd.read_csv(\"./petfinder-pawpularity-score/sample_submission.csv\")[\"Pawpularity\"]\n",
    "test_df[\"C\"] = np.ones(8)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16397\n"
     ]
    }
   ],
   "source": [
    "image_list = {}\n",
    "directory=\"./petfinder-pawpularity-score/train/\"\n",
    "for filename in os.listdir('./petfinder-pawpularity-score/train/'):\n",
    "   # print(filename)\n",
    "    f = os.path.join(directory, filename)\n",
    "    temp=Image.open(f).convert('RGBA')\n",
    "    temp.resize((64,64))\n",
    "    keep=temp.copy()\n",
    "    image_list[filename]=np.array(keep).ravel()\n",
    "    temp.close()\n",
    "#print(image_list[\"6db59cac06bbed063c3fec7b5b70d108.jpg\"])\n",
    "train_x=[]\n",
    "for i in range(train_df.shape[0]):\n",
    "    tmp=train_df.iloc[i]['Id']\n",
    "    tmp=tmp+\".jpg\"\n",
    "    tmp=image_list[tmp]\n",
    "    tmp2=np.array(train_df.iloc[i][['Subject Focus', 'Eyes', \"Face\",\t\"Near\",\t\"Action\", \"Accessory\", \"Group\", \"Collage\", \"Human\", \"Occlusion\", \"Info\", \"Blur\", \"C\"]])\n",
    "    tmp3=np.concatenate((tmp2,tmp))\n",
    "    train_x.append(np.concatenate((tmp3,np.zeros(16397-len(tmp3)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nNEix6tQvb9k"
   },
   "outputs": [],
   "source": [
    "def MSE(preds, test_Y):\n",
    "    return(np.sqrt(np.mean((preds - test_Y)**2)))  #funkcja licząca wielkość błędu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6n5zS0plrvJU"
   },
   "source": [
    "KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fh7V--W0rByd"
   },
   "outputs": [],
   "source": [
    "def KNN(train_X, train_Y, test_X, ks, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute predictions for various k\n",
    "    Args:\n",
    "        train_X: array of shape Ntrain x D\n",
    "        train_Y: array of shape Ntrain\n",
    "        test_X: array of shape Ntest x D\n",
    "        ks: list of integers\n",
    "    Returns:\n",
    "        preds: dict k: predictions for k\n",
    "    \"\"\"\n",
    "    # Cats data to float32\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    test_X = test_X.astype(np.float32)\n",
    "\n",
    "    # Alloc space for results\n",
    "    preds = {}\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing distances... \", end='')\n",
    "    #\n",
    "    # TODO: fill in an efficient distance matrix computation\n",
    "    #    \n",
    "    #dists = np.linalg.norm((train_X[:, None] - test_X), axis = -1)\n",
    "    dists = np.sqrt((train_X**2).sum(1)[:,None] + (test_X**2).sum(1) - 2*train_X.dot(test_X.T))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Sorting... \", end='')\n",
    "    \n",
    "    # TODO: findes closest trainig points\n",
    "    # Hint: use argsort\n",
    "    closest = np.argsort(dists, axis = 0)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing predictions...\", end='')\n",
    "    \n",
    "    targets = train_Y[closest]\n",
    "\n",
    "    for k in ks:\n",
    "        predictions = sstats.tmean(targets[:k])\n",
    "        #Bierzemy średnią zamiast najczęściej występującej wartości\n",
    "        preds[k] = predictions\n",
    "    if verbose:\n",
    "        print(\"Done\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suEE2Jcwr-zO",
    "outputId": "0f460b89-79df-4c8e-cfb2-2ac15a5220b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.584439420062886\n",
      "35.31583064922082\n",
      "35.88227034344399\n",
      "37.13190523289224\n",
      "37.04147305702849\n",
      "37.626997895941116\n",
      "36.623213291233036\n",
      "36.86968349621557\n",
      "36.92476696470709\n",
      "36.45848625605707\n",
      "36.10768937034517\n"
     ]
    }
   ],
   "source": [
    "train_x = np.array(train_df[['Subject Focus', 'Eyes', \"Face\",\t\"Near\",\t\"Action\", \"Accessory\", \"Group\", \"Collage\", \"Human\", \"Occlusion\", \"Info\", \"Blur\", \"C\"]])\n",
    "train_y = np.array(train_df[\"Pawpularity\"])\n",
    "\n",
    "test_x = np.array(test_df[['Subject Focus', 'Eyes', \"Face\",\t\"Near\",\t\"Action\", \"Accessory\", \"Group\", \"Collage\", \"Human\", \"Occlusion\", \"Info\", \"Blur\", \"C\"]])\n",
    "test_y = np.array(test_df[\"Pawpularity\"])\n",
    "\n",
    "preds_KNN = KNN(train_x, train_y, test_x, [1, 3, 5, 7, 9, 11, 13, 15, 17, 19])\n",
    "\n",
    "\n",
    "\n",
    "print(MSE(preds_KNN[1], test_y))\n",
    "print(MSE(preds_KNN[3], test_y))\n",
    "print(MSE(preds_KNN[5], test_y))\n",
    "print(MSE(preds_KNN[7], test_y))\n",
    "print(MSE(preds_KNN[9], test_y))\n",
    "print(MSE(preds_KNN[11], test_y))\n",
    "print(MSE(preds_KNN[13], test_y))\n",
    "print(MSE(preds_KNN[15], test_y))\n",
    "print(MSE(preds_KNN[17], test_y))\n",
    "print(MSE(preds_KNN[19], test_y))\n",
    "# wyniki dla 1,3,5 są lekko lepsze od zwykłej średniej\n",
    "M = np.mean(train_y)\n",
    "\n",
    "print(MSE(M, test_y)) #testujemy jaki byłby błąd gdybyśmy olali features i po prostu używali średniej wartości pawpularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cww3hnRzCD9j"
   },
   "source": [
    "KNN cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1IjgDH1xw5Bj"
   },
   "outputs": [],
   "source": [
    "def KNN_cos(train_X, train_Y, test_X, ks, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute predictions for various k\n",
    "    Args:\n",
    "        train_X: array of shape Ntrain x D\n",
    "        train_Y: array of shape Ntrain\n",
    "        test_X: array of shape Ntest x D\n",
    "        ks: list of integers\n",
    "    Returns:\n",
    "        preds: dict k: predictions for k\n",
    "    \"\"\"\n",
    "    # Cats data to float32\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    test_X = test_X.astype(np.float32)\n",
    "\n",
    "    # Alloc space for results\n",
    "    preds = {}\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing distances... \", end='')\n",
    "    \n",
    "    A_mA = train_X - train_X.mean(1)[:, None]\n",
    "    B_mB = test_X - test_X.mean(1)[:, None]\n",
    "    ssA = (A_mA**2).sum(1)\n",
    "    ssB = (B_mB**2).sum(1)\n",
    "    sims = np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None],ssB[None]))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Sorting... \", end='')\n",
    "    \n",
    "    # TODO: findes closest trainig points\n",
    "    # Hint: use argsort\n",
    "    closest = np.argsort(-sims, axis = 0)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing predictions...\", end='')\n",
    "    \n",
    "    targets = train_Y[closest]\n",
    "\n",
    "    for k in ks:\n",
    "        #Bierzemy średnia zamiast mody\n",
    "        predictions = sstats.tmean(targets[:k])\n",
    "        preds[k] = predictions\n",
    "    if verbose:\n",
    "        print(\"Done\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sAR-bsAyCZqU",
    "outputId": "7f0236a3-0c33-4d1f-dea2-280ec698055e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.339253316956196\n",
      "37.18707369503548\n",
      "36.95626232453709\n",
      "36.56614384947377\n",
      "35.543649278209266\n",
      "35.294566511102126\n",
      "35.11899240460627\n",
      "35.6229255536375\n",
      "36.204320529461675\n",
      "36.138386312001494\n"
     ]
    }
   ],
   "source": [
    "preds_KNN = KNN_cos(train_x, train_y, test_x,[1, 3, 5, 7, 9, 11, 13, 15, 17, 19])\n",
    "print(MSE(preds_KNN[1], test_y))\n",
    "print(MSE(preds_KNN[3], test_y))\n",
    "print(MSE(preds_KNN[5], test_y))\n",
    "print(MSE(preds_KNN[7], test_y))\n",
    "print(MSE(preds_KNN[9], test_y))\n",
    "print(MSE(preds_KNN[11], test_y))\n",
    "print(MSE(preds_KNN[13], test_y))\n",
    "print(MSE(preds_KNN[15], test_y))\n",
    "print(MSE(preds_KNN[17], test_y))\n",
    "print(MSE(preds_KNN[19], test_y))\n",
    "#Wyniki dla 1,5,6,7,8 są lekko lepsze od normalnej średniej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Będziemy robili Knn z kubelkami <30,<60,<90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.63369876 41.39272809 71.94222222]\n"
     ]
    }
   ],
   "source": [
    "train_y_bucket = np.zeros(train_y.shape)\n",
    "train_y_bucket[train_y <= 90] = 2\n",
    "train_y_bucket[train_y <= 60] = 1\n",
    "train_y_bucket[train_y <= 30] = 0\n",
    "train_y_means=np.zeros(3)\n",
    "train_y_means[0]=sstats.tmean(train_y,(0,30))\n",
    "train_y_means[1]=sstats.tmean(train_y,(31,60))\n",
    "train_y_means[2]=sstats.tmean(train_y,(61,90))\n",
    "print(train_y_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_bucket(train_X, train_Y, test_X, ks, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute predictions for various k\n",
    "    Args:\n",
    "        train_X: array of shape Ntrain x D\n",
    "        train_Y: array of shape Ntrain\n",
    "        test_X: array of shape Ntest x D\n",
    "        ks: list of integers\n",
    "    Returns:\n",
    "        preds: dict k: predictions for k\n",
    "    \"\"\"\n",
    "    # Cats data to float32\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    test_X = test_X.astype(np.float32)\n",
    "\n",
    "    # Alloc space for results\n",
    "    preds = {}\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing distances... \", end='')\n",
    "    #\n",
    "    # TODO: fill in an efficient distance matrix computation\n",
    "    #    \n",
    "    #dists = np.linalg.norm((train_X[:, None] - test_X), axis = -1)\n",
    "    dists = np.sqrt((train_X**2).sum(1)[:,None] + (test_X**2).sum(1) - 2*train_X.dot(test_X.T))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Sorting... \", end='')\n",
    "    \n",
    "    # TODO: findes closest trainig points\n",
    "    # Hint: use argsort\n",
    "    closest = np.argsort(dists, axis = 0)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing predictions...\", end='')\n",
    "    \n",
    "    targets = train_Y[closest]\n",
    "\n",
    "    for k in ks:\n",
    "        predictions = sstats.mode(targets[:k])\n",
    "        predictions = predictions[0].ravel()\n",
    "        preds[k] = train_y_means[int(predictions[0])]\n",
    "    if verbose:\n",
    "        print(\"Done\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.244841693979964\n",
      "34.244841693979964\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "36.10768937034517\n"
     ]
    }
   ],
   "source": [
    "train_x = np.array(train_df[['Subject Focus', 'Eyes', \"Face\",\t\"Near\",\t\"Action\", \"Accessory\", \"Group\", \"Collage\", \"Human\", \"Occlusion\", \"Info\", \"Blur\", \"C\"]])\n",
    "train_y = np.array(train_df[\"Pawpularity\"])\n",
    "\n",
    "test_x = np.array(test_df[['Subject Focus', 'Eyes', \"Face\",\t\"Near\",\t\"Action\", \"Accessory\", \"Group\", \"Collage\", \"Human\", \"Occlusion\", \"Info\", \"Blur\", \"C\"]])\n",
    "test_y = np.array(test_df[\"Pawpularity\"])\n",
    "\n",
    "preds_KNN = KNN_bucket(train_x, train_y_bucket, test_x, [1, 3, 5, 7, 9, 11, 13, 15, 17, 19])\n",
    "\n",
    "print(MSE(preds_KNN[1], test_y))\n",
    "print(MSE(preds_KNN[3], test_y))\n",
    "print(MSE(preds_KNN[5], test_y))\n",
    "print(MSE(preds_KNN[7], test_y))\n",
    "print(MSE(preds_KNN[9], test_y))\n",
    "print(MSE(preds_KNN[11], test_y))\n",
    "print(MSE(preds_KNN[13], test_y))\n",
    "print(MSE(preds_KNN[15], test_y))\n",
    "print(MSE(preds_KNN[17], test_y))\n",
    "print(MSE(preds_KNN[19], test_y))\n",
    "# wyniki dla 1,2 są lekko lepsze od zwykłej średniej\n",
    "M = np.mean(train_y)\n",
    "\n",
    "print(MSE(M, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_bucket_cos(train_X, train_Y, test_X, ks, verbose=False):\n",
    "    \"\"\"\n",
    "    Compute predictions for various k\n",
    "    Args:\n",
    "        train_X: array of shape Ntrain x D\n",
    "        train_Y: array of shape Ntrain\n",
    "        test_X: array of shape Ntest x D\n",
    "        ks: list of integers\n",
    "    Returns:\n",
    "        preds: dict k: predictions for k\n",
    "    \"\"\"\n",
    "    # Cats data to float32\n",
    "    train_X = train_X.astype(np.float32)\n",
    "    test_X = test_X.astype(np.float32)\n",
    "\n",
    "    # Alloc space for results\n",
    "    preds = {}\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing distances... \", end='')\n",
    "    \n",
    "    A_mA = train_X - train_X.mean(1)[:, None]\n",
    "    B_mB = test_X - test_X.mean(1)[:, None]\n",
    "    ssA = (A_mA**2).sum(1)\n",
    "    ssB = (B_mB**2).sum(1)\n",
    "    sims = np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None],ssB[None]))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Sorting... \", end='')\n",
    "    \n",
    "    # TODO: findes closest trainig points\n",
    "    # Hint: use argsort\n",
    "    closest = np.argsort(-sims, axis = 0)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Computing predictions...\", end='')\n",
    "    \n",
    "    targets = train_Y[closest]\n",
    "\n",
    "    for k in ks:\n",
    "        predictions = sstats.mode(targets[:k])\n",
    "        predictions = predictions[0].ravel()\n",
    "        preds[k] = train_y_means[int(predictions[0])]\n",
    "    if verbose:\n",
    "        print(\"Done\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.244841693979964\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n",
      "47.63413410503347\n"
     ]
    }
   ],
   "source": [
    "preds_KNN = KNN_bucket_cos(train_x, train_y_bucket, test_x,[1, 3, 5, 7, 9, 11, 13, 15, 17, 19])\n",
    "print(MSE(preds_KNN[1], test_y))\n",
    "print(MSE(preds_KNN[3], test_y))\n",
    "print(MSE(preds_KNN[5], test_y))\n",
    "print(MSE(preds_KNN[7], test_y))\n",
    "print(MSE(preds_KNN[9], test_y))\n",
    "print(MSE(preds_KNN[11], test_y))\n",
    "print(MSE(preds_KNN[13], test_y))\n",
    "print(MSE(preds_KNN[15], test_y))\n",
    "print(MSE(preds_KNN[17], test_y))\n",
    "print(MSE(preds_KNN[19], test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmU6gzu4MC3W"
   },
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBgtTWh3MBvu",
    "outputId": "0a0cd844-7433-4ec9-a9d0-10b981bcfcc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.49720214, -0.15903207, -0.00364125,  0.18000117, -0.35271007,\n",
       "       -0.0865236 , -0.09552653,  0.03689894,  0.17321935, -0.16031754,\n",
       "       -0.05671531, -0.26886885, -3.49277365])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logreg_loss(Theta, X, Y):\n",
    "\n",
    "    ThetaR = Theta.reshape(X.shape[1], 1)\n",
    "\n",
    "    a = X @ ThetaR\n",
    "    sigma = 1 / (1 + np.exp(-a))\n",
    "\n",
    "    nll = -sum(Y * np.log(sigma) + (1 - Y) * np.log(1 - sigma))\n",
    "    grad = X.T @ (sigma - Y)\n",
    "\n",
    "    return nll, grad.reshape(Theta.shape)\n",
    "\n",
    "train_y_logreg = np.zeros(train_y.shape)\n",
    "#train_y_mean=sstats.tmean(train_y,(33,90))\n",
    "#train_y_sum=np.sum(train_y)\n",
    "train_y_logreg[train_y > 99] = 1\n",
    "#klasyfikujemy jako 1 jeśli pawpularity jest duże, i jako 0 jeśli jest małe\n",
    "train_y_logreg = train_y_logreg.reshape(-1,1)\n",
    "\n",
    "Theta0 = np.ones((13,))\n",
    "ThetaOpt = sopt.fmin_l_bfgs_b(\n",
    "    lambda Theta: logreg_loss(Theta, train_x, train_y_logreg), np.array(Theta0)\n",
    ")[0]\n",
    "ThetaOpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NP_a_UcVNnu",
    "outputId": "b858c628-9f1f-45a8-c544-3355b886bc70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.60485355, -3.71043332, -3.94382537, -4.05033235, -4.77201669,\n",
       "       -3.69777095, -4.87821222, -4.08926654])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = test_x @ ThetaOpt #jeśli wynik większy bądź równy 0 to klasyfikujemy jako 1\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IZkKt69VluO",
    "outputId": "a6591a58-7a1a-4240-a31e-1002600f1277"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60, 60, 60, 60, 60, 60, 60, 60])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_logreg = np.full(test_y.shape, 60)\n",
    "preds_logreg[h >= 0] = 100  #z tymi wartościami (20, 40) można pokombinować\n",
    "preds_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDgm-4wFZUWe",
    "outputId": "f10f4629-5706-4abd-d649-cdc97ac2230b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.226759142949803\n"
     ]
    }
   ],
   "source": [
    "print(MSE(preds_logreg, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrF9FYQidkmr"
   },
   "source": [
    "General Robust loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "a9SwRycsZ_u4"
   },
   "outputs": [],
   "source": [
    "def rho(x, alpha, c): #the general robust loss function\n",
    "    if alpha == 0 or alpha == 2:\n",
    "        alpha = alpha + 0.000000001\n",
    "    return(np.abs(alpha-2) / alpha * (((x/c)**2 / np.abs(alpha-2) + 1)**(alpha/2) - 1))\n",
    "\n",
    "def d_rho(x, alpha, c): #and its derivative\n",
    "    if alpha == 0 or alpha == 2:\n",
    "        alpha = alpha + 0.000000001\n",
    "    return(x / c**2 * ((x/c)**2 / np.abs(alpha-2) + 1)**(alpha/2 - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gcj9Aly0dl6K"
   },
   "outputs": [],
   "source": [
    "def linreg_general_loss(Theta, X, Y, alpha, c):\n",
    "    ThetaR = np.array(Theta)\n",
    "    err = (Y - X @ ThetaR)\n",
    "    loss = np.mean(rho(err, alpha, c))\n",
    "\n",
    "    grad_err = d_rho(err, alpha, c)\n",
    "    grad = np.array([np.mean(-grad_err * X[:, i]) for i in range(Theta.shape[0])])\n",
    "    return loss, grad.reshape(Theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGWGzc0PetDl",
    "outputId": "7de0bc71-6d92-4e8f-b774-58f459234ba5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63, 42, 28, ..., 20, 20, 30])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxDb5tknd7bK",
    "outputId": "79c27580-b163-4eed-9b27-3ed2ce863b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.74256400711137\n",
      "40.9578620760133\n",
      "39.867510455636896\n",
      "40.61718324999034\n",
      "38.31332798393121\n",
      "36.3820565240173\n",
      "34.50314235794872\n",
      "33.086588687333304\n",
      "32.19123644602165\n",
      "31.648816890675096\n",
      "31.320061857510698\n",
      "31.117219885880296\n",
      "30.989092946005016\n",
      "30.90461364066636\n",
      "30.84725297305081\n",
      "30.80632080252375\n",
      "30.775910719879597\n",
      "30.752623463080322\n",
      "30.734115201836186\n",
      "30.488868065952406\n"
     ]
    }
   ],
   "source": [
    "Theta0 = np.ones((13,))\n",
    "\n",
    "\n",
    "\n",
    "for alpha in [-3, -2,-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ,13, 14,15,50]:\n",
    "    for c in [1.]:\n",
    "        ThetaOpt, _, dic = sopt.fmin_l_bfgs_b(\n",
    "            lambda Theta: linreg_general_loss(Theta, train_x, train_y, alpha=alpha, c=c), np.array(Theta0)\n",
    "        )\n",
    "        pred = test_x @ ThetaOpt\n",
    "        print(MSE(pred, test_y))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
